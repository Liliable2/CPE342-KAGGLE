{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpytkqlZaBKT",
        "outputId": "dd152c19-bba5-4e57-f260-e9f2bfa545b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Task 5: Account Security Monitoring (Ensemble) ---\n",
            "Data Loaded. Shape: (25889, 124)\n",
            "Engineering features...\n",
            "Scaling features...\n",
            "Training Ensemble Models (Contamination: 0.05)...\n",
            "1. Training Isolation Forest...\n",
            "2. Training One-Class SVM...\n",
            "3. Training Local Outlier Factor...\n",
            "Aggregating votes...\n",
            "\n",
            "--- Ensemble Prediction Summary ---\n",
            "Model Agreement Breakdown:\n",
            "0 Votes (Normal)            23500\n",
            "1 Vote                       1089\n",
            "2 Votes                      1108\n",
            "3 Votes (Strong Anomaly)      192\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Final Decision (Majority Vote):\n",
            "is_anomaly\n",
            "0    24589\n",
            "1     1300\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Successfully saved to 'task5_submission.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def run_task5_pipeline():\n",
        "    print(\"--- Starting Task 5: Account Security Monitoring (Ensemble) ---\")\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 1. LOAD DATA\n",
        "    # ---------------------------------------------------------\n",
        "    try:\n",
        "        df = pd.read_csv('test.csv')\n",
        "        print(f\"Data Loaded. Shape: {df.shape}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: 'task5/test.csv' not found. Please ensure the file exists.\")\n",
        "        return\n",
        "\n",
        "    player_ids = df['id'] if 'id' in df.columns else df.index\n",
        "    # Keep 'id' for submission, but drop it for feature processing\n",
        "    features = df.drop(columns=['id'], errors='ignore')\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 2. FEATURE ENGINEERING\n",
        "    # ---------------------------------------------------------\n",
        "    print(\"Engineering features...\")\n",
        "\n",
        "    # Identify base feature names\n",
        "    base_features = set()\n",
        "    for col in features.columns:\n",
        "        if col[-2:] in ['_1', '_2', '_3', '_4']:\n",
        "            base_features.add(col[:-2])\n",
        "\n",
        "    # Calculate statistics across time steps\n",
        "    for base in base_features:\n",
        "        cols = [f\"{base}_{i}\" for i in range(1, 5)]\n",
        "        if all(c in features.columns for c in cols):\n",
        "            features[f'{base}_std'] = features[cols].std(axis=1)\n",
        "            features[f'{base}_mean'] = features[cols].mean(axis=1)\n",
        "            features[f'{base}_range'] = features[cols].max(axis=1) - features[cols].min(axis=1)\n",
        "\n",
        "    features = features.fillna(0)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 3. SCALING\n",
        "    # ---------------------------------------------------------\n",
        "    print(\"Scaling features...\")\n",
        "    # Select only numeric columns for scaling to avoid errors with object dtypes\n",
        "    numeric_features = features.select_dtypes(include=np.number)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(numeric_features)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 4. ENSEMBLE MODELING\n",
        "    # ---------------------------------------------------------\n",
        "    # Contamination: Expected % of anomalies (e.g., 5%)\n",
        "    contamination_rate = 0.05\n",
        "    print(f\"Training Ensemble Models (Contamination: {contamination_rate})...\")\n",
        "\n",
        "    # --- Model A: Isolation Forest ---\n",
        "    print(\"1. Training Isolation Forest...\")\n",
        "    iso_forest = IsolationForest(\n",
        "        n_estimators=200,\n",
        "        contamination=contamination_rate,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    # Output: -1 (Anomaly), 1 (Normal)\n",
        "    pred_iso = iso_forest.fit_predict(X_scaled)\n",
        "\n",
        "    # --- Model B: One-Class SVM ---\n",
        "    # SVMs can be slow on massive data. If >100k rows, consider SGDOneClassSVM.\n",
        "    print(\"2. Training One-Class SVM...\")\n",
        "    oc_svm = OneClassSVM(\n",
        "        kernel='rbf',\n",
        "        nu=contamination_rate,\n",
        "        gamma='scale'\n",
        "    )\n",
        "    pred_svm = oc_svm.fit_predict(X_scaled)\n",
        "\n",
        "    # --- Model C: Local Outlier Factor (LOF) ---\n",
        "    print(\"3. Training Local Outlier Factor...\")\n",
        "    lof = LocalOutlierFactor(\n",
        "        n_neighbors=20,\n",
        "        contamination=contamination_rate,\n",
        "        n_jobs=-1,\n",
        "        novelty=False # LOF is strictly outlier detection here\n",
        "    )\n",
        "    pred_lof = lof.fit_predict(X_scaled)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 5. VOTING (HARD VOTING)\n",
        "    # ---------------------------------------------------------\n",
        "    print(\"Aggregating votes...\")\n",
        "\n",
        "    # Convert predictions: -1 (Anomaly) -> 1,  1 (Normal) -> 0\n",
        "    # This makes summing them easier.\n",
        "    res_iso = np.where(pred_iso == -1, 1, 0)\n",
        "    res_svm = np.where(pred_svm == -1, 1, 0)\n",
        "    res_lof = np.where(pred_lof == -1, 1, 0)\n",
        "\n",
        "    # Sum votes (0 to 3)\n",
        "    total_votes = res_iso + res_svm + res_lof\n",
        "\n",
        "    # MAJORITY RULE: If 2 or more models agree it's an anomaly, flag it.\n",
        "    # > 1 means 2 or 3 votes.\n",
        "    final_preds = np.where(total_votes > 1, 1, 0)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 6. SUBMISSION\n",
        "    # ---------------------------------------------------------\n",
        "    submission = pd.DataFrame({\n",
        "        'id': player_ids,\n",
        "        'is_anomaly': final_preds\n",
        "    })\n",
        "\n",
        "    print(\"\\n--- Ensemble Prediction Summary ---\")\n",
        "    print(\"Model Agreement Breakdown:\")\n",
        "    print(pd.Series(total_votes).value_counts().sort_index().rename({0: '0 Votes (Normal)', 1: '1 Vote', 2: '2 Votes', 3: '3 Votes (Strong Anomaly)'}))\n",
        "    print(\"\\nFinal Decision (Majority Vote):\")\n",
        "    print(submission['is_anomaly'].value_counts())\n",
        "\n",
        "    submission.to_csv('task5_submission.csv', index=False)\n",
        "    print(\"\\nSuccessfully saved to 'task5_submission.csv'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_task5_pipeline()"
      ]
    }
  ]
}